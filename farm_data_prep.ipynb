{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CV4E Project 1: Preparing Data for Machine Learning\n",
    "\n",
    "This script is used to convert data to a balanced set of images and labels for use in a ResNet model.\n",
    "\n",
    "\n",
    "\n",
    "The data is a set of images in YOLO format (in labels and images folders) \n",
    "and the goal is to convert these to .json files and an image folder for use in the ResNet model.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from itertools import groupby\n",
    "\n",
    "def load_class_names():\n",
    "    return [ 'Pinnipedia',  'Z. californianus',  'Else/Other',  'Gelatinous Object',  'Hydromedusae',  \n",
    "            'P. bachei',  'Ctenophora',  'A. flavidus',  'Cydippida',  'Polyorchis sp.',  'Aequorea sp.',  \n",
    "            'Hexagrammidae',  'Actinopterygii',  'Drift Algae',  'M. Cellularia',  'Scyphomedusae',  \n",
    "            'Eutonina sp.',  'Sarsia sp.',  'Cnidaria',  'Background',  'A. Labiata',  'Embiotocidae',  \n",
    "            'C. aggregata',  'Bolinopsidae',  'C. aggregata (dark morph)',  'R. vacca',  'Fish',  \n",
    "            'F. Fish (unk)',  'Sch-Embiotocidae',  'Ex-Embiotocidae',  'E. Lateralis',  'Sch-C.pallasii',  \n",
    "            'Ex-C. pallasii',  'Clupeidae',  'Ex-Clupeidae',  'B. Frenatus',  'Ex-C. aggregata',  \n",
    "            'Sch-C. aggregata',  'Diving Birds',  'TBD 44',  'Scyphozoa',  'N. breviconis',  'C. pallasii']\n",
    "\n",
    "def get_binary_category(class_id, class_names):\n",
    "    if class_id >= len(class_names):\n",
    "        return 0\n",
    "    \n",
    "    forage_fish_classes = [\n",
    "        'F. Fish (unk)',\n",
    "        'Sch-C.pallasii',\n",
    "        'Ex-C. pallasii', \n",
    "        'Clupeidae',\n",
    "        'Ex-Clupeidae',\n",
    "        'Ex-Embiotocidae',\n",
    "        'Sch-Embiotocidae',\n",
    "        'Sch-E. mordax',\n",
    "        'Ex-E. mordax',\n",
    "    ]\n",
    "    class_name = class_names[class_id]\n",
    "    return 1 if class_name in forage_fish_classes else 0\n",
    "\n",
    "def read_label_safely(label_path):\n",
    "    try:\n",
    "        with open(label_path) as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    parts = line.strip().split()\n",
    "                    if parts:\n",
    "                        return int(parts[0])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {label_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "def create_data_template():\n",
    "    return {\n",
    "        \"info\": {\n",
    "            \"description\": \"ff_test_data\",\n",
    "            \"year\": 2025,\n",
    "            \"contributor\": \"Talen\",\n",
    "            \"date_created\": datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        },\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": [\n",
    "            {\"id\": 1, \"name\": \"forage_fish\"},\n",
    "            {\"id\": 0, \"name\": \"other\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def extract_video_id(filename):\n",
    "    \"\"\"Extract timestamp/video ID from filename\"\"\"\n",
    "    match = re.search(r'(\\d{8}T\\d{6})', filename)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def process_dataset():\n",
    "    img_dir = Path('/Users/talenrimmer/Desktop/All_training_data/fish/images/train')\n",
    "    label_dir = Path('/Users/talenrimmer/Desktop/All_training_data/fish/labels/train')\n",
    "    output_img_dir = Path.cwd() / 'eccv_18_all_images_sm'\n",
    "    \n",
    "    if output_img_dir.exists():\n",
    "        shutil.rmtree(output_img_dir)\n",
    "    output_img_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    class_names = load_class_names()\n",
    "    video_records = {}\n",
    "    processed = 0\n",
    "\n",
    "    # Group by video ID\n",
    "    for img_path in img_dir.glob('*.png'):\n",
    "        label_path = label_dir / f\"{img_path.stem}.txt\"\n",
    "        if not label_path.exists():\n",
    "            continue\n",
    "\n",
    "        class_id = read_label_safely(label_path)\n",
    "        if class_id is None or class_id >= len(class_names):\n",
    "            continue\n",
    "\n",
    "        video_id = extract_video_id(img_path.name)\n",
    "        if video_id is None:\n",
    "            continue\n",
    "\n",
    "        record = {\n",
    "            'image_id': processed,\n",
    "            'file_name': img_path.name,\n",
    "            'category_id': get_binary_category(class_id, class_names),\n",
    "            'img_path': img_path,\n",
    "            'video_id': video_id\n",
    "        }\n",
    "        \n",
    "        if video_id not in video_records:\n",
    "            video_records[video_id] = []\n",
    "        video_records[video_id].append(record)\n",
    "        processed += 1\n",
    "\n",
    "    # Split videos maintaining independence\n",
    "    video_ids = list(video_records.keys())\n",
    "    random.shuffle(video_ids)\n",
    "    \n",
    "    n_videos = len(video_ids)\n",
    "    train_idx = int(0.7 * n_videos)\n",
    "    val_idx = int(0.9 * n_videos)\n",
    "    \n",
    "    train_videos = video_ids[:train_idx]\n",
    "    val_videos = video_ids[train_idx:val_idx]\n",
    "    test_videos = video_ids[val_idx:]\n",
    "\n",
    "    # Combine records by split\n",
    "    train_records = [r for vid in train_videos for r in video_records[vid]]\n",
    "    val_records = [r for vid in val_videos for r in video_records[vid]]\n",
    "    test_records = [r for vid in test_videos for r in video_records[vid]]\n",
    "\n",
    "    # Balance categories within each split\n",
    "    def balance_split(records):\n",
    "        cat_1 = [r for r in records if r['category_id'] == 1]\n",
    "        cat_0 = [r for r in records if r['category_id'] == 0]\n",
    "        n_samples = min(len(cat_1), len(cat_0))\n",
    "        if n_samples == 0:\n",
    "            return []\n",
    "        return random.sample(cat_1, n_samples) + random.sample(cat_0, n_samples)\n",
    "\n",
    "    train_records = balance_split(train_records)\n",
    "    val_records = balance_split(val_records)\n",
    "    test_records = balance_split(test_records)\n",
    "\n",
    "    # Copy images\n",
    "    for record in train_records + val_records + test_records:\n",
    "        shutil.copy2(record['img_path'], output_img_dir / record['file_name'])\n",
    "\n",
    "    splits = {\n",
    "        'train_annotations.json': train_records,\n",
    "        'cis_val_annotations.json': val_records,\n",
    "        'cis_test_annotations.json': test_records\n",
    "    }\n",
    "\n",
    "    print(\"\\nVideo Distribution in Splits:\")\n",
    "    for name, records in splits.items():\n",
    "        videos = set(r['video_id'] for r in records)\n",
    "        cats = Counter(r['category_id'] for r in records)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"Unique videos: {len(videos)}\")\n",
    "        print(f\"Total images: {len(records)}\")\n",
    "        print(f\"Category 1 (forage fish): {cats[1]}\")\n",
    "        print(f\"Category 0 (other): {cats[0]}\")\n",
    "        print(f\"Videos included: {sorted(list(videos))}\")\n",
    "\n",
    "        output = create_data_template()\n",
    "        output[\"images\"] = [{\"id\": r[\"image_id\"], \"file_name\": r[\"file_name\"]} for r in records]\n",
    "        output[\"annotations\"] = [{\"image_id\": r[\"image_id\"], \"category_id\": r[\"category_id\"]} for r in records]\n",
    "        \n",
    "        with open(name, 'w') as f:\n",
    "            json.dump(output, f, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "def load_class_names():\n",
    "    return [ 'Pinnipedia',  'Z. californianus',  'Else/Other',  'Gelatinous Object',  'Hydromedusae',  \n",
    "            'P. bachei',  'Ctenophora',  'A. flavidus',  'Cydippida',  'Polyorchis sp.',  'Aequorea sp.',  \n",
    "            'Hexagrammidae',  'Actinopterygii',  'Drift Algae',  'M. Cellularia',  'Scyphomedusae',  \n",
    "            'Eutonina sp.',  'Sarsia sp.',  'Cnidaria',  'Background',  'A. Labiata',  'Embiotocidae',  \n",
    "            'C. aggregata',  'Bolinopsidae',  'C. aggregata (dark morph)',  'R. vacca',  'Fish',  \n",
    "            'F. Fish (unk)',  'Sch-Embiotocidae',  'Ex-Embiotocidae',  'E. Lateralis',  'Sch-C.pallasii',  \n",
    "            'Ex-C. pallasii',  'Clupeidae',  'Ex-Clupeidae',  'B. Frenatus',  'Ex-C. aggregata',  \n",
    "            'Sch-C. aggregata',  'Diving Birds',  'TBD 44',  'Scyphozoa',  'N. breviconis',  'C. pallasii']\n",
    "\n",
    "def get_binary_category(class_id, class_names):\n",
    "    if class_id >= len(class_names):\n",
    "        return 0\n",
    "    \n",
    "    forage_fish_classes = [\n",
    "        'F. Fish (unk)',\n",
    "        'Sch-C.pallasii',\n",
    "        'Ex-C. pallasii', \n",
    "        'Clupeidae',\n",
    "        'Ex-Clupeidae',\n",
    "        # 'Ex-C. aggregata',\n",
    "        # 'Sch-C. aggregata'\n",
    "        # 'Ex-Embiotocidae',\n",
    "        # 'Sch-Embiotocidae',\n",
    "        'Sch-E. mordax',\n",
    "        'Ex-E. mordax',\n",
    "        # 'Ex-R. vacca',\n",
    "        # 'Sch-R. vacca',\n",
    "    ]\n",
    "    class_name = class_names[class_id]\n",
    "    return 1 if class_name in forage_fish_classes else 0\n",
    "\n",
    "def read_label_safely(label_path):\n",
    "    try:\n",
    "        with open(label_path) as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    parts = line.strip().split()\n",
    "                    if parts:\n",
    "                        return int(parts[0])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {label_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "def create_data_template():\n",
    "    return {\n",
    "        \"info\": {\n",
    "            \"description\": \"ff_test_data\",\n",
    "            \"year\": 2025,\n",
    "            \"contributor\": \"Talen\",\n",
    "            \"date_created\": datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        },\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": [\n",
    "            {\"id\": 1, \"name\": \"forage_fish\"},\n",
    "            {\"id\": 0, \"name\": \"other\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def process_dataset():\n",
    "    img_dir = Path('/Users/talenrimmer/Desktop/All_training_data/fish/images/train')\n",
    "    label_dir = Path('/Users/talenrimmer/Desktop/All_training_data/fish/labels/train')\n",
    "    output_img_dir = Path.cwd() / 'eccv_18_all_images_sm'\n",
    "    \n",
    "    if output_img_dir.exists():\n",
    "        shutil.rmtree(output_img_dir)\n",
    "    output_img_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    class_names = load_class_names()\n",
    "    category_1_samples = []\n",
    "    category_0_samples = []\n",
    "    processed = 0\n",
    "    skipped = 0\n",
    "\n",
    "    for img_path in img_dir.glob('*.png'):\n",
    "        label_path = label_dir / f\"{img_path.stem}.txt\"\n",
    "        if not label_path.exists():\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        class_id = read_label_safely(label_path)\n",
    "        if class_id is None or class_id >= len(class_names):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        record = {\n",
    "            'image_id': processed + 1,\n",
    "            'file_name': img_path.name,\n",
    "            'category_id': get_binary_category(class_id, class_names),\n",
    "            'img_path': img_path\n",
    "        }\n",
    "\n",
    "        if record['category_id'] == 1:\n",
    "            category_1_samples.append(record)\n",
    "        else:\n",
    "            category_0_samples.append(record)\n",
    "        \n",
    "        processed += 1\n",
    "\n",
    "    # Limit category 1 samples to target size\n",
    "    if len(category_1_samples) > 652:\n",
    "        category_1_samples = random.sample(category_1_samples, 652)\n",
    "    \n",
    "    num_positive = len(category_1_samples)\n",
    "    selected_category_0 = random.sample(category_0_samples, num_positive)\n",
    "    balanced_dataset = category_1_samples + selected_category_0\n",
    "    random.shuffle(balanced_dataset)\n",
    "\n",
    "    print(f\"\\nInitial Dataset Summary:\")\n",
    "    print(f\"Total category 1 (forage fish): {len(category_1_samples)}\")\n",
    "    print(f\"Total category 0 (other) available: {len(category_0_samples)}\")\n",
    "    print(f\"Category 0 selected for balance: {len(selected_category_0)}\")\n",
    "    print(f\"Total balanced samples: {len(balanced_dataset)}\")\n",
    "\n",
    "    copied_images = set()\n",
    "    for record in balanced_dataset:\n",
    "        if record['file_name'] not in copied_images:\n",
    "            shutil.copy2(record['img_path'], output_img_dir / record['file_name'])\n",
    "            copied_images.add(record['file_name'])\n",
    "\n",
    "    train_records, temp = train_test_split(balanced_dataset, test_size=0.3, random_state=42)\n",
    "    val_records, test_records = train_test_split(temp, test_size=1/3, random_state=42)\n",
    "\n",
    "    splits = {\n",
    "        'train_annotations.json': train_records,\n",
    "        'cis_val_annotations.json': val_records,\n",
    "        'cis_test_annotations.json': test_records\n",
    "    }\n",
    "\n",
    "    print(\"\\nSplit Distribution:\")\n",
    "    for name, records in splits.items():\n",
    "        counts = Counter(r['category_id'] for r in records)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"Total images: {len(records)}\")\n",
    "        print(f\"Category 1 (forage fish): {counts[1]}\")\n",
    "        print(f\"Category 0 (other): {counts[0]}\")\n",
    "\n",
    "        output = create_data_template()\n",
    "        output[\"images\"] = [{\"id\": r[\"image_id\"], \"file_name\": r[\"file_name\"]} for r in records]\n",
    "        output[\"annotations\"] = [{\"image_id\": r[\"image_id\"], \"category_id\": r[\"category_id\"]} for r in records]\n",
    "        \n",
    "        with open(name, 'w') as f:\n",
    "            json.dump(output, f, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_samples():\n",
    "    # Load JSON file (using train set as example)\n",
    "    with open('train_annotations.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Get image directory\n",
    "    img_dir = Path.cwd() / 'eccv_18_all_images_sm'\n",
    "    \n",
    "    # Separate by category\n",
    "    cat_0_images = []\n",
    "    cat_1_images = []\n",
    "    \n",
    "    for img, ann in zip(data['images'], data['annotations']):\n",
    "        if ann['category_id'] == 0:\n",
    "            cat_0_images.append(img['file_name'])\n",
    "        else:\n",
    "            cat_1_images.append(img['file_name'])\n",
    "    \n",
    "    # Sample 5 random images from each category\n",
    "    cat_0_samples = random.sample(cat_0_images, 5)\n",
    "    cat_1_samples = random.sample(cat_1_images, 5)\n",
    "    \n",
    "    # Create subplot grid\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    \n",
    "    # Plot category 0 samples\n",
    "    for idx, img_name in enumerate(cat_0_samples):\n",
    "        img_path = img_dir / img_name\n",
    "        img = Image.open(img_path)\n",
    "        axes[0, idx].imshow(img)\n",
    "        axes[0, idx].axis('off')\n",
    "        axes[0, idx].set_title(f'Category 0\\n{img_name[:20]}...')\n",
    "    \n",
    "    # Plot category 1 samples\n",
    "    for idx, img_name in enumerate(cat_1_samples):\n",
    "        img_path = img_dir / img_name\n",
    "        img = Image.open(img_path)\n",
    "        axes[1, idx].imshow(img)\n",
    "        axes[1, idx].axis('off')\n",
    "        axes[1, idx].set_title(f'Category 1\\n{img_name[:20]}...')\n",
    "    \n",
    "    plt.suptitle('Sample Images by Category', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def load_json_data(filename):\n",
    "    \"\"\"Load and extract data from JSON annotation file\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data['images'], data['annotations']\n",
    "\n",
    "def extract_timestamp(filename):\n",
    "    \"\"\"Extract timestamp from image filename\"\"\"\n",
    "    match = re.search(r'(\\d{8}T\\d{6})', filename)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def analyze_video_data():\n",
    "    # Load all annotation files\n",
    "    json_files = ['train_annotations.json', \n",
    "                  'cis_val_annotations.json', \n",
    "                  'cis_test_annotations.json']\n",
    "    \n",
    "    # Store all data\n",
    "    all_timestamps = []\n",
    "    all_categories = []\n",
    "    \n",
    "    # Process each JSON file\n",
    "    for json_file in json_files:\n",
    "        images, annotations = load_json_data(json_file)\n",
    "        \n",
    "        # Extract data from each image/annotation pair\n",
    "        for img, ann in zip(images, annotations):\n",
    "            timestamp = extract_timestamp(img['file_name'])\n",
    "            if timestamp:\n",
    "                all_timestamps.append(timestamp)\n",
    "                all_categories.append(ann['category_id'])\n",
    "    \n",
    "    # Create and process dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': all_timestamps,\n",
    "        'category_id': all_categories\n",
    "    })\n",
    "    \n",
    "    # Group and aggregate data\n",
    "    grouped_df = df.groupby('timestamp').agg({\n",
    "        'category_id': ['sum', 'count']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Format columns\n",
    "    grouped_df.columns = ['video_id', 'forage_fish_count', 'number_of_images']\n",
    "    \n",
    "    # Sort and calculate percentages\n",
    "    grouped_df['percentage_forage_fish'] = (\n",
    "        grouped_df['forage_fish_count'] / grouped_df['number_of_images'] * 100\n",
    "    ).round(2)\n",
    "    \n",
    "    # Sort by count\n",
    "    grouped_df = grouped_df.sort_values('forage_fish_count', ascending=False)\n",
    "    \n",
    "    # Display results\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    print(\"\\nForage Fish Analysis by Video:\")\n",
    "    print(grouped_df)\n",
    "    \n",
    "    return grouped_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = analyze_video_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to group the images by video to visualize the distribution of forage fish across videos:\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_annotations():\n",
    "    # Load JSON data from train annotations (contains most data)\n",
    "    with open('train_annotations.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    timestamps = []\n",
    "    categories = []\n",
    "    \n",
    "    # Extract timestamp and category for each image\n",
    "    for img, ann in zip(data['images'], data['annotations']):\n",
    "        # Extract timestamp using regex (matches pattern like '20220709T210155')\n",
    "        match = re.search(r'(\\d{8}T\\d{6})', img['file_name'])\n",
    "        if match:\n",
    "            timestamps.append(match.group(1))\n",
    "            categories.append(ann['category_id'])\n",
    "    \n",
    "    # Create initial dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': timestamps,\n",
    "        'category_id': categories\n",
    "    })\n",
    "    \n",
    "    # Group by timestamp and aggregate data\n",
    "    grouped_df = df.groupby('timestamp').agg({\n",
    "        'category_id': ['sum', 'count']  # sum for forage fish count, count for total images\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Clean up column names\n",
    "    grouped_df.columns = ['video_id', 'forage_fish_count', 'number_of_images']\n",
    "    \n",
    "    # Sort by forage fish count\n",
    "    grouped_df = grouped_df.sort_values('forage_fish_count', ascending=False)\n",
    "    \n",
    "    print(\"\\nForage Fish Counts by Video:\")\n",
    "    print(grouped_df)\n",
    "    \n",
    "    return grouped_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_annotations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
