{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CV4E Project 1: Preparing Data for Machine Learning\n",
    "\n",
    "This project is a first iteration of preparing data for use in a ResNet machine learning model.\n",
    "The data are in the form of a .json file, which were downloaded from BIIGLE and located in the following folder:\n",
    "/Users/talenrimmer/Desktop/CV4E_Code/data/21209-lazo-1-2024-05-22.json\n",
    "\n",
    "The goals of this project are to:\n",
    "- Teach a whole-image classifier to identify images that contain a specific class (forage fish)\n",
    "(If the above is successful, then):\n",
    "a) quantify forage fish into a density estimate (small, medium, large schools)\n",
    "b) identify species of forage fish\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from itertools import groupby\n",
    "\n",
    "def load_class_names():\n",
    "    return [ 'Pinnipedia',  'Z. californianus',  'Else/Other',  'Gelatinous Object',  'Hydromedusae',  \n",
    "            'P. bachei',  'Ctenophora',  'A. flavidus',  'Cydippida',  'Polyorchis sp.',  'Aequorea sp.',  \n",
    "            'Hexagrammidae',  'Actinopterygii',  'Drift Algae',  'M. Cellularia',  'Scyphomedusae',  \n",
    "            'Eutonina sp.',  'Sarsia sp.',  'Cnidaria',  'Background',  'A. Labiata',  'Embiotocidae',  \n",
    "            'C. aggregata',  'Bolinopsidae',  'C. aggregata (dark morph)',  'R. vacca',  'Fish',  \n",
    "            'F. Fish (unk)',  'Sch-Embiotocidae',  'Ex-Embiotocidae',  'E. Lateralis',  'Sch-C.pallasii',  \n",
    "            'Ex-C. pallasii',  'Clupeidae',  'Ex-Clupeidae',  'B. Frenatus',  'Ex-C. aggregata',  \n",
    "            'Sch-C. aggregata',  'Diving Birds',  'TBD 44',  'Scyphozoa',  'N. breviconis',  'C. pallasii']\n",
    "\n",
    "def get_binary_category(class_id, class_names):\n",
    "    if class_id >= len(class_names):\n",
    "        return 0\n",
    "    \n",
    "    forage_fish_classes = [\n",
    "        'F. Fish (unk)',\n",
    "        'Sch-C.pallasii',\n",
    "        'Ex-C. pallasii', \n",
    "        'Clupeidae',\n",
    "        'Ex-Clupeidae',\n",
    "        'Ex-Embiotocidae',\n",
    "        'Sch-Embiotocidae',\n",
    "        'Sch-E. mordax',\n",
    "        'Ex-E. mordax',\n",
    "    ]\n",
    "    class_name = class_names[class_id]\n",
    "    return 1 if class_name in forage_fish_classes else 0\n",
    "\n",
    "def read_label_safely(label_path):\n",
    "    try:\n",
    "        with open(label_path) as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    parts = line.strip().split()\n",
    "                    if parts:\n",
    "                        return int(parts[0])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {label_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "def create_data_template():\n",
    "    return {\n",
    "        \"info\": {\n",
    "            \"description\": \"ff_test_data\",\n",
    "            \"year\": 2025,\n",
    "            \"contributor\": \"Talen\",\n",
    "            \"date_created\": datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        },\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": [\n",
    "            {\"id\": 1, \"name\": \"forage_fish\"},\n",
    "            {\"id\": 0, \"name\": \"other\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def extract_video_id(filename):\n",
    "    \"\"\"Extract timestamp/video ID from filename\"\"\"\n",
    "    match = re.search(r'(\\d{8}T\\d{6})', filename)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def process_dataset():\n",
    "    img_dir = Path('/Users/talenrimmer/Desktop/All_training_data/fish/images/train')\n",
    "    label_dir = Path('/Users/talenrimmer/Desktop/All_training_data/fish/labels/train')\n",
    "    output_img_dir = Path.cwd() / 'eccv_18_all_images_sm'\n",
    "    \n",
    "    if output_img_dir.exists():\n",
    "        shutil.rmtree(output_img_dir)\n",
    "    output_img_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    class_names = load_class_names()\n",
    "    video_records = {}\n",
    "    processed = 0\n",
    "\n",
    "    # Group by video ID\n",
    "    for img_path in img_dir.glob('*.png'):\n",
    "        label_path = label_dir / f\"{img_path.stem}.txt\"\n",
    "        if not label_path.exists():\n",
    "            continue\n",
    "\n",
    "        class_id = read_label_safely(label_path)\n",
    "        if class_id is None or class_id >= len(class_names):\n",
    "            continue\n",
    "\n",
    "        video_id = extract_video_id(img_path.name)\n",
    "        if video_id is None:\n",
    "            continue\n",
    "\n",
    "        record = {\n",
    "            'image_id': processed,\n",
    "            'file_name': img_path.name,\n",
    "            'category_id': get_binary_category(class_id, class_names),\n",
    "            'img_path': img_path,\n",
    "            'video_id': video_id\n",
    "        }\n",
    "        \n",
    "        if video_id not in video_records:\n",
    "            video_records[video_id] = []\n",
    "        video_records[video_id].append(record)\n",
    "        processed += 1\n",
    "\n",
    "    # Split videos maintaining independence\n",
    "    video_ids = list(video_records.keys())\n",
    "    random.shuffle(video_ids)\n",
    "    \n",
    "    n_videos = len(video_ids)\n",
    "    train_idx = int(0.7 * n_videos)\n",
    "    val_idx = int(0.9 * n_videos)\n",
    "    \n",
    "    train_videos = video_ids[:train_idx]\n",
    "    val_videos = video_ids[train_idx:val_idx]\n",
    "    test_videos = video_ids[val_idx:]\n",
    "\n",
    "    # Combine records by split\n",
    "    train_records = [r for vid in train_videos for r in video_records[vid]]\n",
    "    val_records = [r for vid in val_videos for r in video_records[vid]]\n",
    "    test_records = [r for vid in test_videos for r in video_records[vid]]\n",
    "\n",
    "    # Balance categories within each split\n",
    "    def balance_split(records):\n",
    "        cat_1 = [r for r in records if r['category_id'] == 1]\n",
    "        cat_0 = [r for r in records if r['category_id'] == 0]\n",
    "        n_samples = min(len(cat_1), len(cat_0))\n",
    "        if n_samples == 0:\n",
    "            return []\n",
    "        return random.sample(cat_1, n_samples) + random.sample(cat_0, n_samples)\n",
    "\n",
    "    train_records = balance_split(train_records)\n",
    "    val_records = balance_split(val_records)\n",
    "    test_records = balance_split(test_records)\n",
    "\n",
    "    # Copy images\n",
    "    for record in train_records + val_records + test_records:\n",
    "        shutil.copy2(record['img_path'], output_img_dir / record['file_name'])\n",
    "\n",
    "    splits = {\n",
    "        'train_annotations.json': train_records,\n",
    "        'cis_val_annotations.json': val_records,\n",
    "        'cis_test_annotations.json': test_records\n",
    "    }\n",
    "\n",
    "    print(\"\\nVideo Distribution in Splits:\")\n",
    "    for name, records in splits.items():\n",
    "        videos = set(r['video_id'] for r in records)\n",
    "        cats = Counter(r['category_id'] for r in records)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"Unique videos: {len(videos)}\")\n",
    "        print(f\"Total images: {len(records)}\")\n",
    "        print(f\"Category 1 (forage fish): {cats[1]}\")\n",
    "        print(f\"Category 0 (other): {cats[0]}\")\n",
    "        print(f\"Videos included: {sorted(list(videos))}\")\n",
    "\n",
    "        output = create_data_template()\n",
    "        output[\"images\"] = [{\"id\": r[\"image_id\"], \"file_name\": r[\"file_name\"]} for r in records]\n",
    "        output[\"annotations\"] = [{\"image_id\": r[\"image_id\"], \"category_id\": r[\"category_id\"]} for r in records]\n",
    "        \n",
    "        with open(name, 'w') as f:\n",
    "            json.dump(output, f, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "def load_class_names():\n",
    "    return [ 'Pinnipedia',  'Z. californianus',  'Else/Other',  'Gelatinous Object',  'Hydromedusae',  \n",
    "            'P. bachei',  'Ctenophora',  'A. flavidus',  'Cydippida',  'Polyorchis sp.',  'Aequorea sp.',  \n",
    "            'Hexagrammidae',  'Actinopterygii',  'Drift Algae',  'M. Cellularia',  'Scyphomedusae',  \n",
    "            'Eutonina sp.',  'Sarsia sp.',  'Cnidaria',  'Background',  'A. Labiata',  'Embiotocidae',  \n",
    "            'C. aggregata',  'Bolinopsidae',  'C. aggregata (dark morph)',  'R. vacca',  'Fish',  \n",
    "            'F. Fish (unk)',  'Sch-Embiotocidae',  'Ex-Embiotocidae',  'E. Lateralis',  'Sch-C.pallasii',  \n",
    "            'Ex-C. pallasii',  'Clupeidae',  'Ex-Clupeidae',  'B. Frenatus',  'Ex-C. aggregata',  \n",
    "            'Sch-C. aggregata',  'Diving Birds',  'TBD 44',  'Scyphozoa',  'N. breviconis',  'C. pallasii']\n",
    "\n",
    "def get_binary_category(class_id, class_names):\n",
    "    if class_id >= len(class_names):\n",
    "        return 0\n",
    "    \n",
    "    forage_fish_classes = [\n",
    "        'F. Fish (unk)',\n",
    "        'Sch-C.pallasii',\n",
    "        'Ex-C. pallasii', \n",
    "        'Clupeidae',\n",
    "        'Ex-Clupeidae',\n",
    "        # 'Ex-C. aggregata',\n",
    "        # 'Sch-C. aggregata'\n",
    "        # 'Ex-Embiotocidae',\n",
    "        # 'Sch-Embiotocidae',\n",
    "        'Sch-E. mordax',\n",
    "        'Ex-E. mordax',\n",
    "        # 'Ex-R. vacca',\n",
    "        # 'Sch-R. vacca',\n",
    "    ]\n",
    "    class_name = class_names[class_id]\n",
    "    return 1 if class_name in forage_fish_classes else 0\n",
    "\n",
    "def read_label_safely(label_path):\n",
    "    try:\n",
    "        with open(label_path) as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    parts = line.strip().split()\n",
    "                    if parts:\n",
    "                        return int(parts[0])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {label_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "def create_data_template():\n",
    "    return {\n",
    "        \"info\": {\n",
    "            \"description\": \"ff_test_data\",\n",
    "            \"year\": 2025,\n",
    "            \"contributor\": \"Talen\",\n",
    "            \"date_created\": datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        },\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": [\n",
    "            {\"id\": 1, \"name\": \"forage_fish\"},\n",
    "            {\"id\": 0, \"name\": \"other\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def process_dataset():\n",
    "    img_dir = Path('/Users/talenrimmer/Desktop/All_training_data/fish/images/train')\n",
    "    label_dir = Path('/Users/talenrimmer/Desktop/All_training_data/fish/labels/train')\n",
    "    output_img_dir = Path.cwd() / 'eccv_18_all_images_sm'\n",
    "    \n",
    "    if output_img_dir.exists():\n",
    "        shutil.rmtree(output_img_dir)\n",
    "    output_img_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    class_names = load_class_names()\n",
    "    category_1_samples = []\n",
    "    category_0_samples = []\n",
    "    processed = 0\n",
    "    skipped = 0\n",
    "\n",
    "    for img_path in img_dir.glob('*.png'):\n",
    "        label_path = label_dir / f\"{img_path.stem}.txt\"\n",
    "        if not label_path.exists():\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        class_id = read_label_safely(label_path)\n",
    "        if class_id is None or class_id >= len(class_names):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        record = {\n",
    "            'image_id': processed + 1,\n",
    "            'file_name': img_path.name,\n",
    "            'category_id': get_binary_category(class_id, class_names),\n",
    "            'img_path': img_path\n",
    "        }\n",
    "\n",
    "        if record['category_id'] == 1:\n",
    "            category_1_samples.append(record)\n",
    "        else:\n",
    "            category_0_samples.append(record)\n",
    "        \n",
    "        processed += 1\n",
    "\n",
    "    # Limit category 1 samples to target size\n",
    "    if len(category_1_samples) > 652:\n",
    "        category_1_samples = random.sample(category_1_samples, 652)\n",
    "    \n",
    "    num_positive = len(category_1_samples)\n",
    "    selected_category_0 = random.sample(category_0_samples, num_positive)\n",
    "    balanced_dataset = category_1_samples + selected_category_0\n",
    "    random.shuffle(balanced_dataset)\n",
    "\n",
    "    print(f\"\\nInitial Dataset Summary:\")\n",
    "    print(f\"Total category 1 (forage fish): {len(category_1_samples)}\")\n",
    "    print(f\"Total category 0 (other) available: {len(category_0_samples)}\")\n",
    "    print(f\"Category 0 selected for balance: {len(selected_category_0)}\")\n",
    "    print(f\"Total balanced samples: {len(balanced_dataset)}\")\n",
    "\n",
    "    copied_images = set()\n",
    "    for record in balanced_dataset:\n",
    "        if record['file_name'] not in copied_images:\n",
    "            shutil.copy2(record['img_path'], output_img_dir / record['file_name'])\n",
    "            copied_images.add(record['file_name'])\n",
    "\n",
    "    train_records, temp = train_test_split(balanced_dataset, test_size=0.3, random_state=42)\n",
    "    val_records, test_records = train_test_split(temp, test_size=1/3, random_state=42)\n",
    "\n",
    "    splits = {\n",
    "        'train_annotations.json': train_records,\n",
    "        'cis_val_annotations.json': val_records,\n",
    "        'cis_test_annotations.json': test_records\n",
    "    }\n",
    "\n",
    "    print(\"\\nSplit Distribution:\")\n",
    "    for name, records in splits.items():\n",
    "        counts = Counter(r['category_id'] for r in records)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"Total images: {len(records)}\")\n",
    "        print(f\"Category 1 (forage fish): {counts[1]}\")\n",
    "        print(f\"Category 0 (other): {counts[0]}\")\n",
    "\n",
    "        output = create_data_template()\n",
    "        output[\"images\"] = [{\"id\": r[\"image_id\"], \"file_name\": r[\"file_name\"]} for r in records]\n",
    "        output[\"annotations\"] = [{\"image_id\": r[\"image_id\"], \"category_id\": r[\"category_id\"]} for r in records]\n",
    "        \n",
    "        with open(name, 'w') as f:\n",
    "            json.dump(output, f, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_samples():\n",
    "    # Load JSON file (using train set as example)\n",
    "    with open('train_annotations.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Get image directory\n",
    "    img_dir = Path.cwd() / 'eccv_18_all_images_sm'\n",
    "    \n",
    "    # Separate by category\n",
    "    cat_0_images = []\n",
    "    cat_1_images = []\n",
    "    \n",
    "    for img, ann in zip(data['images'], data['annotations']):\n",
    "        if ann['category_id'] == 0:\n",
    "            cat_0_images.append(img['file_name'])\n",
    "        else:\n",
    "            cat_1_images.append(img['file_name'])\n",
    "    \n",
    "    # Sample 5 random images from each category\n",
    "    cat_0_samples = random.sample(cat_0_images, 5)\n",
    "    cat_1_samples = random.sample(cat_1_images, 5)\n",
    "    \n",
    "    # Create subplot grid\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    \n",
    "    # Plot category 0 samples\n",
    "    for idx, img_name in enumerate(cat_0_samples):\n",
    "        img_path = img_dir / img_name\n",
    "        img = Image.open(img_path)\n",
    "        axes[0, idx].imshow(img)\n",
    "        axes[0, idx].axis('off')\n",
    "        axes[0, idx].set_title(f'Category 0\\n{img_name[:20]}...')\n",
    "    \n",
    "    # Plot category 1 samples\n",
    "    for idx, img_name in enumerate(cat_1_samples):\n",
    "        img_path = img_dir / img_name\n",
    "        img = Image.open(img_path)\n",
    "        axes[1, idx].imshow(img)\n",
    "        axes[1, idx].axis('off')\n",
    "        axes[1, idx].set_title(f'Category 1\\n{img_name[:20]}...')\n",
    "    \n",
    "    plt.suptitle('Sample Images by Category', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def load_json_data(filename):\n",
    "    \"\"\"Load and extract data from JSON annotation file\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data['images'], data['annotations']\n",
    "\n",
    "def extract_timestamp(filename):\n",
    "    \"\"\"Extract timestamp from image filename\"\"\"\n",
    "    match = re.search(r'(\\d{8}T\\d{6})', filename)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def analyze_video_data():\n",
    "    # Load all annotation files\n",
    "    json_files = ['train_annotations.json', \n",
    "                  'cis_val_annotations.json', \n",
    "                  'cis_test_annotations.json']\n",
    "    \n",
    "    # Store all data\n",
    "    all_timestamps = []\n",
    "    all_categories = []\n",
    "    \n",
    "    # Process each JSON file\n",
    "    for json_file in json_files:\n",
    "        images, annotations = load_json_data(json_file)\n",
    "        \n",
    "        # Extract data from each image/annotation pair\n",
    "        for img, ann in zip(images, annotations):\n",
    "            timestamp = extract_timestamp(img['file_name'])\n",
    "            if timestamp:\n",
    "                all_timestamps.append(timestamp)\n",
    "                all_categories.append(ann['category_id'])\n",
    "    \n",
    "    # Create and process dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': all_timestamps,\n",
    "        'category_id': all_categories\n",
    "    })\n",
    "    \n",
    "    # Group and aggregate data\n",
    "    grouped_df = df.groupby('timestamp').agg({\n",
    "        'category_id': ['sum', 'count']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Format columns\n",
    "    grouped_df.columns = ['video_id', 'forage_fish_count', 'number_of_images']\n",
    "    \n",
    "    # Sort and calculate percentages\n",
    "    grouped_df['percentage_forage_fish'] = (\n",
    "        grouped_df['forage_fish_count'] / grouped_df['number_of_images'] * 100\n",
    "    ).round(2)\n",
    "    \n",
    "    # Sort by count\n",
    "    grouped_df = grouped_df.sort_values('forage_fish_count', ascending=False)\n",
    "    \n",
    "    # Display results\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    print(\"\\nForage Fish Analysis by Video:\")\n",
    "    print(grouped_df)\n",
    "    \n",
    "    return grouped_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = analyze_video_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to group the images by video to visualize the distribution of forage fish across videos:\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_annotations():\n",
    "    # Load JSON data from train annotations (contains most data)\n",
    "    with open('train_annotations.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    timestamps = []\n",
    "    categories = []\n",
    "    \n",
    "    # Extract timestamp and category for each image\n",
    "    for img, ann in zip(data['images'], data['annotations']):\n",
    "        # Extract timestamp using regex (matches pattern like '20220709T210155')\n",
    "        match = re.search(r'(\\d{8}T\\d{6})', img['file_name'])\n",
    "        if match:\n",
    "            timestamps.append(match.group(1))\n",
    "            categories.append(ann['category_id'])\n",
    "    \n",
    "    # Create initial dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': timestamps,\n",
    "        'category_id': categories\n",
    "    })\n",
    "    \n",
    "    # Group by timestamp and aggregate data\n",
    "    grouped_df = df.groupby('timestamp').agg({\n",
    "        'category_id': ['sum', 'count']  # sum for forage fish count, count for total images\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Clean up column names\n",
    "    grouped_df.columns = ['video_id', 'forage_fish_count', 'number_of_images']\n",
    "    \n",
    "    # Sort by forage fish count\n",
    "    grouped_df = grouped_df.sort_values('forage_fish_count', ascending=False)\n",
    "    \n",
    "    print(\"\\nForage Fish Counts by Video:\")\n",
    "    print(grouped_df)\n",
    "    \n",
    "    return grouped_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_annotations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
