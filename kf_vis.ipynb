{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CV4E Project 1: Preparing Data for Machine Learning\n",
    "\n",
    "This project is a first iteration of preparing data for use in a ResNet machine learning model.\n",
    "The data are in the form of a .json file, which were downloaded from BIIGLE and located in the following folder:\n",
    "/Users/talenrimmer/Desktop/CV4E_Code/data/21209-lazo-1-2024-05-22.json\n",
    "\n",
    "The goals of this project are to:\n",
    "- Teach a whole-image classifier to identify images that contain a specific class (forage fish)\n",
    "(If the above is successful, then):\n",
    "a) quantify forage fish into a density estimate (small, medium, large schools)\n",
    "b) identify species of forage fish\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now open every .json file in the directory \"/Users/talenrimmer/Desktop/CV4E_Code/data/\" as a file and use the function data = json.load(file) to load the data into a variable.\n",
    "import os\n",
    "import json\n",
    "directory = \"/Users/talenrimmer/Desktop/CV4E_Code/data/\"\n",
    "# Now we will create a list of all the files in the directory\n",
    "files = os.listdir(directory)\n",
    "# Now we will iterate over every .json file in the diretory, load the data into a variable, and print the JSON structure\n",
    "for file in files:\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(directory + file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is the old code, that I use to open a single file:\n",
    "\n",
    "# Import json lbrary and load in the json file from my local directory \n",
    "# import json\n",
    "# with open(\"/Users/talenrimmer/Desktop/CV4E_Code/data/21209-lazo-1-2024-05-22.json\",'r') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "    # Print the JSON structure\n",
    "### print(json.dumps(data[\"annotations\"], indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The .json file has the data in the form of a dictionary, so I will print each key (images, annotations, and categories), and define all three in a pandas dataframe:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "imagedf = pd.DataFrame(data[\"images\"])\n",
    "\n",
    "annotationsdf = pd.DataFrame(data[\"annotations\"])\n",
    "\n",
    "categoriesdf = pd.DataFrame(data[\"categories\"])\n",
    "\n",
    "# Print the first 5 rows of each dataframe to see what the data looks like\n",
    "categoriesdf.sample(5)\n",
    "#And the number of columns:\n",
    "annotationsdf.columns\n",
    "\n",
    "# Rename the columns in each dataframe so they all represent their id\n",
    "categoriesdf.rename(columns={'id': 'category_id'}, inplace=True)\n",
    "\n",
    "annotationsdf.rename(columns={'id': 'annotations_id'}, inplace=True)\n",
    "\n",
    "imagedf.rename(columns={'id': 'image_id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I will merge the image and annotations dataframes together to create one dataframe that contains all the data\n",
    "merged_df = pd.merge(annotationsdf, imagedf, on='image_id', how='outer')\n",
    "\n",
    "#print the length of the merged dataframe to see how many rows it has:\n",
    "\n",
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique image_id counts in each DataFrame\n",
    "annotations_count = annotationsdf['image_id'].nunique()\n",
    "images_count = imagedf['image_id'].nunique()\n",
    "merged_count = merged_df['image_id'].nunique()\n",
    "\n",
    "print(f\"Unique image_id in annotationsdf: {annotations_count}\")\n",
    "print(f\"Unique image_id in imagedf: {images_count}\")\n",
    "print(f\"Unique image_id in merged_df: {merged_count}\")\n",
    "\n",
    "# Verify all rows are retained\n",
    "annotations_rows = len(annotationsdf)\n",
    "images_rows = len(imagedf)\n",
    "merged_rows = len(merged_df)\n",
    "\n",
    "print(f\"Rows in annotationsdf: {annotations_rows}\")\n",
    "print(f\"Rows in imagedf: {images_rows}\")\n",
    "print(f\"Rows in merged_df: {merged_rows}\")\n",
    "\n",
    "# Check for missing values in image_id column\n",
    "missing_image_ids = merged_df['image_id'].isna().sum()\n",
    "print(f\"Missing image_id rows in merged_df: {missing_image_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all rows and images by image_id:\n",
    "all_images = pd.merge(imagedf, annotationsdf,\n",
    "         how = 'outer', on = 'image_id')\n",
    "\n",
    "all_images.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to check for any NA values!\n",
    "\n",
    "# Check for NA values in the 'name' column\n",
    "na_values = all_images['annotations_id'].isna()\n",
    "\n",
    "# Display rows where 'name' column has NA values\n",
    "missing_values = all_images[na_values]\n",
    "\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging annotations and images by image_id:\n",
    "\n",
    "annotations_images = pd.merge(annotationsdf, imagedf,\n",
    "         how = 'left', on = 'image_id')\n",
    "\n",
    "merged_df = pd.merge(annotations_images, categoriesdf,\n",
    "         how = 'left', on = \"category_id\")\n",
    "\n",
    "merged_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting data such that we just see the IDs, the file name, and the name of the animal\n",
    "shortened_df = merged_df[[\"image_id\", \"category_id\", \"annotations_id\", \"file_name\", \"name\"]]\n",
    "# min_df = merged_df[[\"annotations_id\", \"file_name\", \"name\"]]\n",
    "\n",
    "shortened_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of names to mark as True\n",
    "# UPDATE 20/1/2025 - I removed Forage fish from the dataset (attempt to make it easier to identify other forage fish)\n",
    "# UPDATE 25/1/2025 - removing forage fish left too few annotations to work with, so I'm adding them back in\n",
    "forage_fish_names = [\n",
    "    'Forage Fish',\n",
    "    'Sch. A. personatus',\n",
    "    'Ex. C. Pallasii',\n",
    "    'Sch. C. Pallasii',\n",
    "    'Ex. C. aggregata',\n",
    "    'Sch. C. aggregata',\n",
    "    'A. personatus (Pacific Sand Lance)',\n",
    "    'Ex. A. personatus'\n",
    "]\n",
    "\n",
    "#UPDATE: here's one with just 'obvious' forage fish that I made:\n",
    "# forage_fish_names = [\n",
    "#     'Obv_ff'\n",
    "# ]\n",
    "\n",
    "# Create a new column 'forage fish' with True/False values based on the condition\n",
    "shortened_df['is_forage_fish'] = shortened_df['name'].isin(forage_fish_names)\n",
    "\n",
    "shortened_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#and then remove rows that contain the file_name values \"GOPR3002.JPG\" and \"GOPR3270.JPG\". These contain images that have annotations of both non-forage fish and forage fish, which we don't want.\n",
    "# It would be an issue because we're classifying the images as a whole, not the individual annotations.\n",
    "shortened_df = shortened_df[~shortened_df['file_name'].isin(['GOPR3002.JPG', 'GOPR3270.JPG'])]\n",
    "\n",
    "#Now query the dataframe to make sure the rows have been removed (return false if the rows are still present):\n",
    "assert not shortened_df['file_name'].isin(['GOPR3002.JPG', 'GOPR3270.JPG']).any()\n",
    "\n",
    "#Remove rows with a specific image_id value (these are removed because they contain erronous images)\n",
    "shortened_df = shortened_df[~shortened_df['image_id'].isin(['5993725', '5992343'])]\n",
    "#Now query the dataframe to make sure the rows have been removed (return false if the rows are still present):\n",
    "assert not shortened_df['image_id'].isin(['5993725', '5992343']).any()\n",
    "\n",
    "shortened_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now we plot a historgram of the 'is_forage_fish' column to see the distribution of True and False values\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Count the occurrences of True and False in the 'forage fish' column\n",
    "# counts = shortened_df['is_forage_fish'].value_counts()\n",
    "# counts\n",
    "\n",
    "# # Plot a histogram\n",
    "# counts.plot(kind='bar')\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('Forage Fish (True or False)')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Proportion of False vs True in Forage Fish Column')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "REVISED BELOW 29.01.25\n",
    "This code chunk is Important! It checks for missing images in the images folder and adds them to the dataframe with some values.\n",
    "This matters because up until this point, we've only had the images that were annotated in the dataset. We want to add all the images that we know also exist in the images folder, \n",
    "but that don't have the same name as the ones we already have. These new images will be our 'empty' images.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# First we find the images from the images folder\n",
    "for image in os.listdir('/Users/talenrimmer/Desktop/CV4E_Code/images'):\n",
    "    image_without_ext = image.replace('.jpg', '') # remove the file extension from the image name\n",
    "    image_without_ext = int(image_without_ext)\n",
    "    # print(image_without_ext)\n",
    "    # print(type(image_without_ext))\n",
    "    # print(type(shortened_df['image_id'].values[0]))\n",
    "    if not image_without_ext in shortened_df['image_id'].values: #this says 'if the image id is not in the dataframe'\n",
    "        #add it as a row to an object with columns that are the same as the dataframe:\n",
    "        new_row = {'image_id': image_without_ext, 'category_id': 'NaN', 'annotations_id': 'NaN', 'file_name': 'NaN', 'name': 'Empty', 'is_forage_fish': False}\n",
    "        new_row = pd.DataFrame(new_row, index=[0]) #and call the new object a pandas dataframe\n",
    "    # else: \n",
    "    #     print('False')\n",
    "    # add new row to dataframe\n",
    "        shortened_df = pd.concat([shortened_df, new_row], ignore_index=True) # Now we add the newly created dataframe to the old dataframe!\n",
    "\n",
    "     #now we view to make sure we have both 'true' and 'false' values for the 'is_forage_fish' column, to make sure the new rows were added correctly: \n",
    "shortened_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "REVISED BELOW 29.01.25\n",
    "This code chunk is Important! It checks for missing images in the images folder and adds them to the dataframe with some values.\n",
    "This matters because up until this point, we've only had the images that were annotated in the dataset. We want to add all the images that we know also exist in the images folder, \n",
    "but that don't have the same name as the ones we already have. These new images will be our 'empty' images.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# # First we find the images from the images folder\n",
    "# for image in os.listdir('/Users/talenrimmer/Desktop/CV4E_Code/images'):\n",
    "#     image_without_ext = image.replace('.jpg', '') # remove the file extension from the image name\n",
    "#     image_without_ext = int(image_without_ext)\n",
    "#     # print(image_without_ext)\n",
    "#     # print(type(image_without_ext))\n",
    "#     # print(type(shortened_df['image_id'].values[0]))\n",
    "#     if not image_without_ext in shortened_df['image_id'].values: #this says 'if the image id is not in the dataframe'\n",
    "#         #add it as a row to an object with columns that are the same as the dataframe:\n",
    "#         new_row = {'image_id': image_without_ext, 'category_id': 'NaN', 'annotations_id': 'NaN', 'file_name': 'NaN', 'name': 'Empty', 'is_forage_fish': False}\n",
    "#         new_row = pd.DataFrame(new_row, index=[0]) #and call the new object a pandas dataframe\n",
    "#     # else: \n",
    "#     #     print('False')\n",
    "#     # add new row to dataframe\n",
    "#         shortened_df = pd.concat([shortened_df, new_row], ignore_index=True) # Now we add the newly created dataframe to the old dataframe!\n",
    "\n",
    "#      #now we view to make sure we have both 'true' and 'false' values for the 'is_forage_fish' column, to make sure the new rows were added correctly: \n",
    "# shortened_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "REVISED BELOW 29.01.25\n",
    "This code chunk is Important! It checks for missing images in the images folder and adds them to the dataframe with some values.\n",
    "This matters because up until this point, we've only had the images that were annotated in the dataset. We want to add all the images that we know also exist in the images folder, \n",
    "but that don't have the same name as the ones we already have. These new images will be our 'empty' images.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# First we find the images from the images folder\n",
    "for image in os.listdir('/Users/talenrimmer/Desktop/CV4E_Code/images'):\n",
    "    # Skip hidden files and non-image files\n",
    "    if image.startswith('.') or not image.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        continue\n",
    "    image_without_ext = image.replace('.jpg', '')\n",
    "    image_without_ext = int(image_without_ext)\n",
    "    \n",
    "    if not image_without_ext in shortened_df['image_id'].values: #this says 'if the image id is not in the dataframe'\n",
    "        #add it as a row to an object with columns that are the same as the dataframe:\n",
    "        new_row = {'image_id': image_without_ext, 'category_id': 'NaN', 'annotations_id': 'NaN', 'file_name': 'NaN', 'name': 'Empty', 'is_forage_fish': False}\n",
    "        new_row = pd.DataFrame(new_row, index=[0]) #and call the new object a pandas dataframe\n",
    "    # else: \n",
    "    #     print('False')\n",
    "    # add new row to dataframe\n",
    "        shortened_df = pd.concat([shortened_df, new_row], ignore_index=True) # Now we add the newly created dataframe to the old dataframe!\n",
    "\n",
    "     #now we view to make sure we have both 'true' and 'false' values for the 'is_forage_fish' column, to make sure the new rows were added correctly: \n",
    "shortened_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we check our overall false vs true values in the 'is_forage_fish' column:\n",
    "import matplotlib.pyplot as plt\n",
    "# Count the occurrences of True and False in the 'forage fish' column\n",
    "counts = shortened_df['is_forage_fish'].value_counts()\n",
    "counts\n",
    "\n",
    "# Plot a histogram\n",
    "counts.plot(kind='bar')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Forage Fish (True or False)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Proportion of False vs True in Forage Fish Column')\n",
    "\n",
    "\"\"\"\n",
    "Turn on the below code if you want to see this frequency plot of the 'is_forage_fish' column\n",
    "\"\"\"\n",
    "# Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Creating a list of value counts for each name\n",
    "histogram = shortened_df['name'].value_counts()\n",
    "\n",
    "histogram\n",
    "# So we can see that there are >2700 empty images in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code chunk is important! \n",
    "It adds a new column to the dataframe that is a numerical representation of the 'is_forage_fish' column.\n",
    "\"\"\"\n",
    "# Now we make a new column called 'forage_num' that will be 1 if the animal is a forage fish and 0 if it is not\n",
    "shortened_df['forage_num'] = shortened_df['is_forage_fish'].astype(int) #this converts the boolean values to integers\n",
    "\n",
    "# saving shortened_df to a .csv file\n",
    "# shortened_df.to_csv('shortened_df.csv')\n",
    "\n",
    "# Now we sum all the values in the 'forage_num' column to get the total number of forage fish for each image_id. \n",
    "forage_fish_counts = shortened_df.groupby('image_id')['forage_num'].sum()\n",
    "\n",
    "#and we make this a pandas dataframe:\n",
    "forage_fish_counts = pd.DataFrame(forage_fish_counts)\n",
    "\n",
    "\"\"\"\n",
    "Here's code that can find the 5 largest values in the 'forage_fish_counts' dataframe\n",
    "It's useful if you want to see the images with the most forage fish (or a different taxa) in them.\n",
    "\"\"\"\n",
    "# now we view the 5 max values of the forage fish counts:\n",
    "# forage_fish_counts.nlargest(20)\n",
    "\n",
    "# now we export the dataframe as a .csv file:\n",
    "# forage_fish_counts.to_csv('forage_fish_counts.csv')\n",
    "\n",
    "#and now we add this to our shortened_df\n",
    "# shortened_df = pd.merge(shortened_df, forage_fish_counts, on='image_id')\n",
    "# shortened_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can Visualize the distribution of forage_num in the dataset, plotting the value counts of forage_num \n",
    "# that are not 0 and sorting from smallest to largest schools:\n",
    "test = forage_fish_counts[forage_fish_counts['forage_num']!=0].value_counts().sort_index().plot(kind='bar', figsize=(20,10))\n",
    "# plt.xlabel('Number of Forage Fish')\n",
    "# we can see that our largest school size is 2610, and our smallest is 4 fish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets visualize our largest school size:\n",
    "forage_fish_counts[forage_fish_counts['forage_num']>2000] #this shows us the row with the largest school size\n",
    "\n",
    "shortened_df[shortened_df['image_id']==5993932][\"file_name\"] #this shows us the file name of the image with the largest school size\n",
    "\n",
    "# Now we'll do the same with the image_id of \"5992288\":\n",
    "shortened_df[shortened_df['image_id']==5992288][\"file_name\"] #this shows us the file name of the image with the largest school size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we look at the image with the most forage fish:\n",
    "from IPython.display import Image, display\n",
    "\n",
    "#The code below calls on the image with the largest school. BUT IMPORTANT: do NOT sync with github if you run this code, as the image is too large to upload to github.\n",
    "\n",
    "# display(Image(filename='/Users/talenrimmer/Desktop/CV4E_Code/images/5993932.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we also want to check the number of images that are not empty\n",
    "num_no0 = forage_fish_counts[forage_fish_counts['forage_num']!=0]\n",
    "\n",
    "# [\"image_id\"]\n",
    "# test\n",
    "# for imagename in test:\n",
    "#     print(imagename)\n",
    "num_no0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on the above, we saw there are some images that contained very few forage fish that I'd like to inspect. \n",
    "So, we're going to find the file names for those images\n",
    "\"\"\"\n",
    "# Now we're subsetting the data for just rows that contain values of forage_num <30 and >0:\n",
    "forage_fish_counts_30 = forage_fish_counts[forage_fish_counts['forage_num']<30]\n",
    "\n",
    "forage_fish_counts_30 = forage_fish_counts_30[forage_fish_counts_30['forage_num']>0]\n",
    "forage_fish_counts_30\n",
    "\n",
    "#Now we're going to find all the rows in shortened_df that contain the image_id values in forage_fish_counts_30:\n",
    "shortened_df_30 = shortened_df[shortened_df['image_id'].isin(forage_fish_counts_30.index)]\n",
    "shortened_df_30\n",
    "\n",
    "#And now we can use this info to discuss with our annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculate number of images in forage_fish_counts that = True, and downsample the false to match:\n",
    "\n",
    "# Now we calculate number of images in forage_fish_counts that have the value True\n",
    "forage_fish_counts_true = forage_fish_counts[forage_fish_counts['forage_num']!=0]\n",
    "\n",
    "# Now we remove the row that has the image_id 5992343, as it's erronous:\n",
    "forage_fish_counts_true = forage_fish_counts_true[forage_fish_counts_true.index != 5992343]\n",
    "forage_fish_counts_true\n",
    "# Now we downsample the false values to match the number of true values:\n",
    "forage_fish_counts_false = forage_fish_counts[forage_fish_counts['forage_num']==0].sample(n=len(forage_fish_counts_true))\n",
    "forage_fish_counts_false\n",
    "\n",
    "#Now we create a training dataset with 63 images from the forage_fish_counts_true and from the forage_fish_counts_false dataset, called \"training_set\"\n",
    "training_set = pd.concat([forage_fish_counts_true, forage_fish_counts_false])\n",
    "\n",
    "# Now we concatenate the two dataframes:\n",
    "# forage_fish_counts_ds = pd.concat([forage_fish_counts_true, forage_fish_counts_false])\n",
    "# forage_fish_counts_ds\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking rows of forage fish in true:\n",
    "forage_fish_counts_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking rows of forage fish in false:\n",
    "forage_fish_counts_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we create a training, test, and val set from the forage_fish_counts_true and forage_fish_counts_false datasets:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the 'forage_fish_counts_true' dataframe\n",
    "true_train, true_temp = train_test_split(forage_fish_counts_true, test_size=0.3, random_state=38)\n",
    "true_val, true_test = train_test_split(true_temp, test_size=(1/3), random_state=38)\n",
    "\n",
    "# Split the 'forage_fish_counts_false' dataframe\n",
    "false_train, false_temp = train_test_split(forage_fish_counts_false, test_size=0.3, random_state=38)\n",
    "false_val, false_test = train_test_split(false_temp, test_size=(1/3), random_state=38)\n",
    "\n",
    "# Combine the corresponding splits from both datasets\n",
    "# train = pd.concat([true_train, false_train])\n",
    "# val = pd.concat([true_val, false_val])\n",
    "# test = pd.concat([true_test, false_test])\n",
    "\n",
    "# # Verify the sizes\n",
    "# print(f\"Train size: {len(train)}\")\n",
    "# print(f\"Validation size: {len(val)}\")\n",
    "# print(f\"Test size: {len(test)}\")\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# # creating lists for true train and other combinations (THIS WAS THE ORIGINAL CODE THAT WORKED:)\n",
    "# #creating lists for each combination:\n",
    "df_list = [[true_train, \"train\", \"ff\"],\n",
    "[false_train, \"train\", \"empty\"],\n",
    "[true_val, \"val\", \"ff\"],\n",
    "[false_val, \"val\", \"empty\"],\n",
    "[true_test, \"test\", \"ff\"],\n",
    "[false_test, \"test\", \"empty\"]\n",
    "]\n",
    "# for df, split_type, class_type in df_list:\n",
    "\n",
    "#     for image_id in df.index.tolist():\n",
    "#         # shutil.copy(f'/Users/talenrimmer/Desktop/CV4E_Code/images/{image_id}.jpg', f'/Users/talenrimmer/Desktop/CV4E_Code/data_split/{split_type}/{class_type}')\n",
    "#         #split type\n",
    "#         #class \n",
    "#         src_img = f'/Users/talenrimmer/Desktop/CV4E_Code/images/{image_id}.jpg'\n",
    "#         dst_img = f'/Users/talenrimmer/Desktop/CV4E_Code/data_split/{split_type}/{class_type}'\n",
    "#         Path(dst_img).mkdir(parents=True, exist_ok=True) #Checking if the destination img folder exists, if not, create it (for each ff and empty folder)\n",
    "#         shutil.copy(src_img, dst_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create a plot to view the total number of images in the training, validation, and test sets:\n",
    "train_size = len(true_train) + len(false_train)\n",
    "val_size = len(true_val) + len(false_val)\n",
    "test_size = len(true_test) + len(false_test)\n",
    "#now we print these three values:\n",
    "print(f\"Train size: {train_size}\")\n",
    "print(f\"Validation size: {val_size}\")\n",
    "print(f\"Test size: {test_size}\")\n",
    "\n",
    "\n",
    "# concatinate .jpg to the image_id column\n",
    "# Looping through train, and add images that correspond to the image_id to a new folder (called train)\n",
    "# Looping through val, and add images that correspond to the image_id to a new folder (called val)\n",
    "# # Looping through test, and add images that correspond to the image_id to a new folder (called test)\n",
    "\n",
    "# # make the train dataframe into a list\n",
    "# train_list = train.index.tolist()\n",
    "# val_list = val.index.tolist()\n",
    "# test_list = test.index.tolist()\n",
    "\n",
    "# import shutil\n",
    "\n",
    "# # Looping through train, and add images that correspond to the image_id to a new folder (called train)\n",
    "# for image_id in train_list:\n",
    "#     shutil.copy(f'/Users/talenrimmer/Desktop/CV4E_Code/images/{image_id}.jpg', f'/Users/talenrimmer/Desktop/CV4E_Code/data_split/train/ff')\n",
    "#     shutil.copy(f'/Users/talenrimmer/Desktop/CV4E_Code/images/{image_id}.jpg', f'/Users/talenrimmer/Desktop/CV4E_Code/data_split/train/empty')\n",
    "\n",
    "\n",
    "# for image_id in val_list:\n",
    "#     shutil.copy(f'/Users/talenrimmer/Desktop/CV4E_Code/images/{image_id}.jpg', f'/Users/talenrimmer/Desktop/CV4E_Code/data_split/val/ff')\n",
    "#     shutil.copy(f'/Users/talenrimmer/Desktop/CV4E_Code/images/{image_id}.jpg', f'/Users/talenrimmer/Desktop/CV4E_Code/data_split/val/empty')\n",
    "\n",
    "# for image_id in test_list:\n",
    "#     shutil.copy(f'/Users/talenrimmer/Desktop/CV4E_Code/images/{image_id}.jpg', f'/Users/talenrimmer/Desktop/CV4E_Code/data_split/test/ff')\n",
    "#     shutil.copy(f'/Users/talenrimmer/Desktop/CV4E_Code/images/{image_id}.jpg', f'/Users/talenrimmer/Desktop/CV4E_Code/data_split/test/empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {\n",
    "    \"info\": {\n",
    "        \"description\": \"ff_test_data\",\n",
    "        \"year\": 2025,\n",
    "        \"contributor\": \"Talen\",\n",
    "        \"date_created\": \"2025-01-10\"\n",
    "    },\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": []\n",
    "}\n",
    "\n",
    "\n",
    "cis_val_data = {\n",
    "    \"info\": {\n",
    "        \"description\": \"ff_test_data\",\n",
    "        \"year\": 2025,\n",
    "        \"contributor\": \"Talen\",\n",
    "        \"date_created\": \"2025-01-10\"\n",
    "    },\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": []\n",
    "}\n",
    "\n",
    "\n",
    "cis_test_data = {\n",
    "    \"info\": {\n",
    "        \"description\": \"ff_test_data\",\n",
    "        \"year\": 2025,\n",
    "        \"contributor\": \"Talen\",\n",
    "        \"date_created\": \"2025-01-10\"\n",
    "    },\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categories = [{\n",
    "    \"id\": 1,\n",
    "    \"name\": \"ff\"\n",
    "},{\n",
    "    \"id\": 2,\n",
    "    \"name\": \"empty\"\n",
    "}]\n",
    "\n",
    "\n",
    "# Train data:\n",
    "for image_id in true_train.index.tolist():\n",
    "    image = {\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": f\"{image_id}.jpg\",\n",
    "    }\n",
    "    train_data[\"images\"].append(image)\n",
    "    \n",
    "    annotation = {  \n",
    "        \"image_id\": image_id,\n",
    "        \"category_id\": 1\n",
    "    }\n",
    "    train_data[\"annotations\"].append(annotation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for image_id in false_train.index.tolist():\n",
    "    image = {\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": f\"{image_id}.jpg\",\n",
    "    }\n",
    "    train_data[\"images\"].append(image)\n",
    "    \n",
    "    annotation = {  \n",
    "        \"image_id\": image_id,\n",
    "        \"category_id\": 0\n",
    "    }\n",
    "    train_data[\"annotations\"].append(annotation)\n",
    "    \n",
    "train_data[\"categories\"] = categories\n",
    "\n",
    "# Now we save the \"train_data\" as a .json file called \"train_annotations\" to the local directory:\n",
    "with open('/Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/train_annotations.json', 'w') as outfile:\n",
    "    json.dump(train_data, outfile)\n",
    "\n",
    "\n",
    "\n",
    "# with open('train_data.json', 'w') as outfile:\n",
    "#     json.dump(train_data, outfile)\n",
    "\n",
    "\n",
    "\n",
    "# Val data:\n",
    "for image_id in true_val.index.tolist():\n",
    "    image = {\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": f\"{image_id}.jpg\",\n",
    "    }\n",
    "    cis_val_data[\"images\"].append(image)\n",
    "    \n",
    "    annotation = {  \n",
    "        \"image_id\": image_id,\n",
    "        \"category_id\": 1\n",
    "    }\n",
    "    cis_val_data[\"annotations\"].append(annotation)\n",
    "    \n",
    "\n",
    "for image_id in false_val.index.tolist():\n",
    "    image = {\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": f\"{image_id}.jpg\",\n",
    "    }\n",
    "    cis_val_data[\"images\"].append(image)\n",
    "    \n",
    "    annotation = {  \n",
    "        \"image_id\": image_id,\n",
    "        \"category_id\": 0\n",
    "    }\n",
    "    cis_val_data[\"annotations\"].append(annotation)\n",
    "    \n",
    "cis_val_data[\"categories\"] = categories\n",
    "\n",
    "# Now we save the \"cis_val_data\" as a .json file called \"cis_val_annotations\" to the local directory:\n",
    "with open('/Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/cis_val_annotations.json', 'w') as outfile:\n",
    "    json.dump(cis_val_data, outfile)\n",
    "\n",
    "\n",
    "# Test data:\n",
    "for image_id in true_test.index.tolist():\n",
    "    image = {\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": f\"{image_id}.jpg\",\n",
    "    }\n",
    "    cis_test_data[\"images\"].append(image)\n",
    "    \n",
    "    annotation = {  \n",
    "        \"image_id\": image_id,\n",
    "        \"category_id\": 1\n",
    "    }\n",
    "    cis_test_data[\"annotations\"].append(annotation)\n",
    "\n",
    "\n",
    "for image_id in false_test.index.tolist():\n",
    "    image = {\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": f\"{image_id}.jpg\",\n",
    "    }\n",
    "    cis_test_data[\"images\"].append(image)\n",
    "    \n",
    "    annotation = {  \n",
    "        \"image_id\": image_id,\n",
    "        \"category_id\": 0\n",
    "    }\n",
    "    cis_test_data[\"annotations\"].append(annotation)\n",
    "\n",
    "\n",
    "cis_test_data[\"categories\"] = categories\n",
    "\n",
    "# Now we save the \"cis_test_data\" as a .json file called \"cis_test_annotations\" to the local directory:\n",
    "with open('/Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/cis_test_annotations.json', 'w') as outfile:\n",
    "    json.dump(cis_test_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code chunk transfers all images that match the image_id values in the 'train_data', 'cis_val_data', and 'cis_test_data' dictionaries \n",
    "# to a new folder called 'eccv_18_all_images_sm':\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Now, we check if a folder called 'eccv_18_all_images_sm' exists, and if it doesn't, we create it:\n",
    "if not os.path.exists('/Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_all_images_sm'):\n",
    "    os.mkdir('/Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_all_images_sm')\n",
    "\n",
    "#Now re remove all existing images from the 'eccv_18_all_images_sm' folder:\n",
    "for image in os.listdir('/Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_all_images_sm'):\n",
    "     os.remove(f'/Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_all_images_sm/{image}')\n",
    "\n",
    "# Now we copy all image_ids that are contained in the 'train_data', 'cis_val_data', and 'cis_test_data' dictionaries, and add them to the 'eccv_18_all_images_sm' folder:\n",
    "for image_id in train_data[\"images\"]:\n",
    "    shutil.copy(f'/Users/talenrimmer/Desktop/CV4E_Code/images/{image_id[\"id\"]}.jpg', '/Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_all_images_sm')\n",
    "\n",
    "for image_id in cis_val_data[\"images\"]:\n",
    "    shutil.copy(f'/Users/talenrimmer/Desktop/CV4E_Code/images/{image_id[\"id\"]}.jpg', '/Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_all_images_sm')\n",
    "\n",
    "for image_id in cis_test_data[\"images\"]:\n",
    "    shutil.copy(f'/Users/talenrimmer/Desktop/CV4E_Code/images/{image_id[\"id\"]}.jpg', '/Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_all_images_sm')\n",
    "    \n",
    "    \n",
    "# Now re rename the 'images_sm' folder to 'eccv_18_all_images_sm':\n",
    "# mv /Users/talenrimmer/Desktop/CV4E_Code/images_sm /Users/talenrimmer/Desktop/CV4E_Code/eccv_18_all_images_sm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
