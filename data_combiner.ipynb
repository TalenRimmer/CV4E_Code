{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Jupyter notebook will combine the .json files from the kf_vis and farm_data_prep notebooks\n",
    "\n",
    "\"\"\"\n",
    "Ok great! \n",
    "\n",
    "I now have two datasets that both contain identically-named json and image folders.\n",
    "\n",
    "The first dataset (called gopro dataset) has the following structure:\n",
    "\n",
    "annotation files pathnames:\n",
    "\n",
    "test file: /Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_annotation_files/cis_test_annotations.json\n",
    "train file: /Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_annotation_files/train_annotations.json\n",
    "val file: /Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_annotation_files/cis_val_annotations.json\n",
    "\n",
    "image files pathnames:\n",
    "/Users/talenrimmer/Desktop/CV4E_Code/images\n",
    "\n",
    "\n",
    "The second dataset (called farm dataset) has the following structure:\n",
    "\n",
    "annotation files pathnames:\n",
    "\n",
    "test file: /Users/talenrimmer/Desktop/CV4E_Code/cis_test_annotations.json\n",
    "train file: /Users/talenrimmer/Desktop/CV4E_Code/train_annotations.json\n",
    "val file: /Users/talenrimmer/Desktop/CV4E_Code/cis_val_annotations.json\n",
    "\n",
    "image files pathnames:\n",
    "/Users/talenrimmer/Desktop/CV4E_Code/eccv_18_all_images_sm\n",
    "\n",
    "provide code to combine these two datasets into a single dataset with the following structure:\n",
    "\n",
    "create a new folder called combined_dataset\n",
    "create a new folder called eccv_18_annotation_files inside combined_dataset\n",
    "combine the test json files from the two datasets into a single file called cis_test_annotations.json inside eccv_18_annotation_files\n",
    "combine the train json files from the two datasets into a single file called train_annotations.json inside eccv_18_annotation_files\n",
    "combine the val json files from the two datasets into a single file called cis_val_annotations.json inside eccv_18_annotation_files\n",
    "\n",
    "create a new folder called eccv_18_all_images_sm inside combined_dataset\n",
    "\n",
    "Then print the total number of files in each file type (json train, test, val, and images) in the combined datasets.\n",
    "Print a method to verify that the combined dataset is correct.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"Create new directory structure\"\"\"\n",
    "    base_dir = Path('/Users/talenrimmer/Desktop/CV4E_Code/combined_dataset')\n",
    "    ann_dir = base_dir / 'eccv_18_annotation_files'\n",
    "    img_dir = base_dir / 'eccv_18_all_images_sm'\n",
    "    \n",
    "    for dir in [base_dir, ann_dir, img_dir]:\n",
    "        if dir.exists():\n",
    "            shutil.rmtree(dir)\n",
    "        dir.mkdir(parents=True)\n",
    "    \n",
    "    return base_dir, ann_dir, img_dir\n",
    "\n",
    "def safe_copy_image(src_path, dst_path):\n",
    "    \"\"\"Copy image file with error handling\"\"\"\n",
    "    try:\n",
    "        if src_path.exists():\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {src_path}: {e}\")\n",
    "    return False\n",
    "\n",
    "def merge_datasets():\n",
    "    # Setup paths\n",
    "    gopro_ann_dir = Path('/Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_annotation_files')\n",
    "    farm_ann_dir = Path('/Users/talenrimmer/Desktop/CV4E_Code')\n",
    "    gopro_img_dir = Path('/Users/talenrimmer/Desktop/CV4E_Code/images')\n",
    "    farm_img_dir = Path('/Users/talenrimmer/Desktop/CV4E_Code/eccv_18_all_images_sm')\n",
    "    \n",
    "    # Create directories\n",
    "    base_dir, ann_dir, img_dir = setup_directories()\n",
    "    \n",
    "    # Track skipped items\n",
    "    total_skipped = {'gopro': 0, 'farm': 0}\n",
    "    \n",
    "    # Process each split\n",
    "    splits = ['train_annotations.json', 'cis_val_annotations.json', 'cis_test_annotations.json']\n",
    "    \n",
    "    for split in splits:\n",
    "        print(f\"\\nProcessing {split}...\")\n",
    "        \n",
    "        # Load JSONs\n",
    "        gopro_data = json.load(open(gopro_ann_dir / split))\n",
    "        farm_data = json.load(open(farm_ann_dir / split))\n",
    "        \n",
    "        # Track valid images\n",
    "        valid_images = []\n",
    "        valid_annotations = []\n",
    "        next_id = 1\n",
    "        split_skipped = {'gopro': 0, 'farm': 0}\n",
    "        \n",
    "        # Process GoPro images\n",
    "        for img, ann in zip(gopro_data['images'], gopro_data['annotations']):\n",
    "            src_path = gopro_img_dir / img['file_name']\n",
    "            dst_path = img_dir / img['file_name']\n",
    "            \n",
    "            if safe_copy_image(src_path, dst_path):\n",
    "                img['id'] = next_id\n",
    "                ann['image_id'] = next_id\n",
    "                valid_images.append(img)\n",
    "                valid_annotations.append(ann)\n",
    "                next_id += 1\n",
    "            else:\n",
    "                split_skipped['gopro'] += 1\n",
    "                total_skipped['gopro'] += 1\n",
    "        \n",
    "        # Process Farm images\n",
    "        for img, ann in zip(farm_data['images'], farm_data['annotations']):\n",
    "            src_path = farm_img_dir / img['file_name']\n",
    "            dst_path = img_dir / img['file_name']\n",
    "            \n",
    "            if safe_copy_image(src_path, dst_path):\n",
    "                img['id'] = next_id\n",
    "                ann['image_id'] = next_id\n",
    "                valid_images.append(img)\n",
    "                valid_annotations.append(ann)\n",
    "                next_id += 1\n",
    "            else:\n",
    "                split_skipped['farm'] += 1\n",
    "                total_skipped['farm'] += 1\n",
    "        \n",
    "        # Create merged data\n",
    "        merged_data = {\n",
    "            \"info\": gopro_data.get('info', {}),\n",
    "            \"images\": valid_images,\n",
    "            \"annotations\": valid_annotations,\n",
    "            \"categories\": gopro_data.get('categories', [])\n",
    "        }\n",
    "        \n",
    "        # Save merged JSON\n",
    "        with open(ann_dir / split, 'w') as f:\n",
    "            json.dump(merged_data, f, indent=4)\n",
    "            \n",
    "        print(f\"Images processed: {len(valid_images)}\")\n",
    "        print(f\"Annotations processed: {len(valid_annotations)}\")\n",
    "        print(f\"Images skipped in this split - GoPro: {split_skipped['gopro']}, Farm: {split_skipped['farm']}\")\n",
    "        cats = Counter(ann['category_id'] for ann in valid_annotations)\n",
    "        print(f\"Category distribution: {dict(cats)}\")\n",
    "    \n",
    "    # Final summary\n",
    "    print(f\"\\nTotal images in combined directory: {len(list(img_dir.glob('*.png')))}\")\n",
    "    print(f\"Total images skipped - GoPro: {total_skipped['gopro']}, Farm: {total_skipped['farm']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merge_datasets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
