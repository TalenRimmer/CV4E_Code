{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Jupyter notebook will combine the .json files from the kf_vis and farm_data_prep notebooks\n",
    "\n",
    "\"\"\"\n",
    "Ok great! \n",
    "\n",
    "I now have two datasets that both contain identically-named json and image folders.\n",
    "\n",
    "The first dataset (called gopro dataset) has the following structure:\n",
    "\n",
    "annotation files pathnames:\n",
    "\n",
    "test file: /Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_annotation_files/cis_test_annotations.json\n",
    "train file: /Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_annotation_files/train_annotations.json\n",
    "val file: /Users/talenrimmer/Desktop/CV4E_Code/ct_classifier_outputs/eccv_18_annotation_files/cis_val_annotations.json\n",
    "\n",
    "image files pathnames:\n",
    "/Users/talenrimmer/Desktop/CV4E_Code/images\n",
    "\n",
    "\n",
    "The second dataset (called farm dataset) has the following structure:\n",
    "\n",
    "annotation files pathnames:\n",
    "\n",
    "test file: /Users/talenrimmer/Desktop/CV4E_Code/cis_test_annotations.json\n",
    "train file: /Users/talenrimmer/Desktop/CV4E_Code/train_annotations.json\n",
    "val file: /Users/talenrimmer/Desktop/CV4E_Code/cis_val_annotations.json\n",
    "\n",
    "image files pathnames:\n",
    "/Users/talenrimmer/Desktop/CV4E_Code/eccv_18_all_images_sm\n",
    "\n",
    "provide code to combine these two datasets into a single dataset with the following structure:\n",
    "\n",
    "create a new folder called combined_dataset\n",
    "create a new folder called eccv_18_annotation_files inside combined_dataset\n",
    "combine the test json files from the two datasets into a single file called cis_test_annotations.json inside eccv_18_annotation_files\n",
    "combine the train json files from the two datasets into a single file called train_annotations.json inside eccv_18_annotation_files\n",
    "combine the val json files from the two datasets into a single file called cis_val_annotations.json inside eccv_18_annotation_files\n",
    "\n",
    "create a new folder called eccv_18_all_images_sm inside combined_dataset\n",
    "\n",
    "Then print the total number of files in each file type (json train, test, val, and images) in the combined datasets.\n",
    "Print a method to verify that the combined dataset is correct.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Jan 22nd 2:52pm\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "def setup_directories():\n",
    "    # =====================================================================\n",
    "    # DIRECTORY 1: CHANGE BASE OUTPUT DIRECTORY HERE\n",
    "    # Default: /mnt/class_data/group4/talen/combined_imbalanced\n",
    "    # =====================================================================\n",
    "    base_dir = Path('/mnt/class_data/group4/talen/combined_imbalanced')\n",
    "    ann_dir = base_dir / 'eccv_18_annotation_files'\n",
    "    img_dir = base_dir / 'eccv_18_all_images_sm'\n",
    "    \n",
    "    print(\"\\n=== OUTPUT DIRECTORIES ===\")\n",
    "    print(f\"Base directory: {base_dir}\")\n",
    "    print(f\"Annotation directory: {ann_dir}\")\n",
    "    print(f\"Image directory: {img_dir}\")\n",
    "    print(\"=========================\\n\")\n",
    "    \n",
    "    for dir in [base_dir, ann_dir, img_dir]:\n",
    "        if dir.exists():\n",
    "            shutil.rmtree(dir)\n",
    "        dir.mkdir(parents=True)\n",
    "    \n",
    "    return base_dir, ann_dir, img_dir\n",
    "\n",
    "def count_category_1(json_path):\n",
    "    \"\"\"Count category 1 examples in JSON file\"\"\"\n",
    "    try:\n",
    "        with open(json_path) as f:\n",
    "            data = json.load(f)\n",
    "        return sum(1 for ann in data['annotations'] if ann['category_id'] == 1)\n",
    "    except FileNotFoundError:\n",
    "        return 0\n",
    "\n",
    "def safe_copy_image(src_path, dst_path, copied_files):\n",
    "    \"\"\"Copy image if it doesn't exist in destination\"\"\"\n",
    "    try:\n",
    "        if src_path.exists() and dst_path.name not in copied_files:\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "            copied_files.add(dst_path.name)\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {src_path}: {e}\")\n",
    "    return False\n",
    "\n",
    "def split_by_ratio(data, ratios=[0.7, 0.2, 0.1]):\n",
    "    \"\"\"Split data by given ratios\"\"\"\n",
    "    n = len(data)\n",
    "    indices = list(range(n))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    cuts = [int(n * ratio) for ratio in ratios]\n",
    "    cuts = [sum(cuts[:i]) for i in range(len(cuts) + 1)]\n",
    "    \n",
    "    return [\n",
    "        [data[i] for i in indices[start:end]]\n",
    "        for start, end in zip(cuts[:-1], cuts[1:])\n",
    "    ]\n",
    "\n",
    "def merge_datasets():\n",
    "    # =====================================================================\n",
    "    # DIRECTORY 2: CHANGE INPUT DIRECTORIES HERE\n",
    "    # =====================================================================\n",
    "    gopro_ann_dir = Path('/mnt/class_data/group4/talen/gopro_preJan21/eccv_18_annotation_files')\n",
    "    farm_ann_dir = Path('/mnt/class_data/group4/talen/farm_output/eccv_18_annotation_files')\n",
    "    gopro_img_dir = Path('/mnt/class_data/group4/talen/gopro_preJan21/eccv_18_all_images_sm')\n",
    "    farm_img_dir = Path('/mnt/class_data/group4/talen/farm_output/eccv_18_all_images_sm')      # Farm images path\n",
    "    \n",
    "    print(\"\\n=== INPUT DIRECTORIES ===\")\n",
    "    print(f\"GoPro annotations: {gopro_ann_dir}\")\n",
    "    print(f\"Farm annotations: {farm_ann_dir}\")\n",
    "    print(f\"GoPro images: {gopro_img_dir}\")\n",
    "    print(f\"Farm images: {farm_img_dir}\")\n",
    "    print(\"========================\\n\")\n",
    "    \n",
    "    # Print initial category 1 counts\n",
    "    print(\"\\nInitial Category 1 Counts:\")\n",
    "    print(\"\\nGoPro Dataset:\")\n",
    "    for split in ['train_annotations.json', 'cis_val_annotations.json', 'cis_test_annotations.json']:\n",
    "        count = count_category_1(gopro_ann_dir / split)\n",
    "        print(f\"{split}: {count} category 1 examples\")\n",
    "\n",
    "    print(\"\\nFarm Dataset:\")\n",
    "    for split in ['train_annotations.json', 'cis_val_annotations.json', 'cis_test_annotations.json']:\n",
    "        count = count_category_1(farm_ann_dir / split)\n",
    "        print(f\"{split}: {count} category 1 examples\")\n",
    "\n",
    "    base_dir, ann_dir, img_dir = setup_directories()\n",
    "    \n",
    "    # Track copied files\n",
    "    copied_files = set()\n",
    "    \n",
    "    # Collect all valid images and annotations\n",
    "    all_images = []\n",
    "    all_annotations = []\n",
    "    next_id = 1\n",
    "    \n",
    "    # Process GoPro dataset\n",
    "    for split in ['train_annotations.json', 'cis_val_annotations.json', 'cis_test_annotations.json']:\n",
    "        data = json.load(open(gopro_ann_dir / split))\n",
    "        for img, ann in zip(data['images'], data['annotations']):\n",
    "            src_path = gopro_img_dir / img['file_name']\n",
    "            dst_path = img_dir / img['file_name']\n",
    "            if safe_copy_image(src_path, dst_path, copied_files):\n",
    "                img['id'] = next_id\n",
    "                ann['image_id'] = next_id\n",
    "                all_images.append(img)\n",
    "                all_annotations.append(ann)\n",
    "                next_id += 1\n",
    "\n",
    "    # Process Farm dataset\n",
    "    farm_splits = {\n",
    "        'train': 'train_annotations.json',\n",
    "        'val': 'cis_val_annotations.json',\n",
    "        'test': 'cis_test_annotations.json'\n",
    "    }\n",
    "    for split in farm_splits.values():\n",
    "        try:\n",
    "            data = json.load(open(farm_ann_dir / split))\n",
    "            for img, ann in zip(data['images'], data['annotations']):\n",
    "                src_path = farm_img_dir / img['file_name']\n",
    "                dst_path = img_dir / img['file_name']\n",
    "                if safe_copy_image(src_path, dst_path, copied_files):\n",
    "                    img['id'] = next_id\n",
    "                    ann['image_id'] = next_id\n",
    "                    all_images.append(img)\n",
    "                    all_annotations.append(ann)\n",
    "                    next_id += 1\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {split} not found in farm dataset\")\n",
    "\n",
    "    # Separate by category\n",
    "    cat_1_records = []\n",
    "    cat_0_records = []\n",
    "    for img, ann in zip(all_images, all_annotations):\n",
    "        record = {'image': img, 'annotation': ann}\n",
    "        if ann['category_id'] == 1:\n",
    "            cat_1_records.append(record)\n",
    "        else:\n",
    "            cat_0_records.append(record)\n",
    "\n",
    "    # Split each category 70/20/10\n",
    "    cat_1_splits = split_by_ratio(cat_1_records)\n",
    "    cat_0_splits = split_by_ratio(cat_0_records)\n",
    "\n",
    "    # Combine splits\n",
    "    splits_data = {\n",
    "        'train_annotations.json': (cat_1_splits[0], cat_0_splits[0]),\n",
    "        'cis_val_annotations.json': (cat_1_splits[1], cat_0_splits[1]),\n",
    "        'cis_test_annotations.json': (cat_1_splits[2], cat_0_splits[2])\n",
    "    }\n",
    "\n",
    "    # Save splits\n",
    "    for filename, (cat_1_records, cat_0_records) in splits_data.items():\n",
    "        records = cat_1_records + cat_0_records\n",
    "        output = {\n",
    "            \"info\": {\"description\": \"Combined dataset\"},\n",
    "            \"images\": [r['image'] for r in records],\n",
    "            \"annotations\": [r['annotation'] for r in records],\n",
    "            \"categories\": [\n",
    "                {\"id\": 1, \"name\": \"forage_fish\"},\n",
    "                {\"id\": 0, \"name\": \"other\"}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        with open(ann_dir / filename, 'w') as f:\n",
    "            json.dump(output, f, indent=4)\n",
    "        \n",
    "        print(f\"\\n{filename}:\")\n",
    "        print(f\"Category 1: {len(cat_1_records)}\")\n",
    "        print(f\"Category 0: {len(cat_0_records)}\")\n",
    "        print(f\"Total: {len(records)}\")\n",
    "\n",
    "    print(f\"\\nTotal unique images copied: {len(copied_files)}\")\n",
    "    print(f\"Total images in combined directory: {len(list(img_dir.glob('*.png')))}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merge_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Jan 29th - but needs to be tested! if not working, use the code above.\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "def setup_directories():\n",
    "    # =====================================================================\n",
    "    # DIRECTORY 1: CHANGE BASE OUTPUT DIRECTORY HERE\n",
    "    # Default: /mnt/class_data/group4/talen/combined_imbalanced\n",
    "    # =====================================================================\n",
    "    base_dir = Path('/mnt/class_data/group4/talen/combined_imbalanced')\n",
    "    ann_dir = base_dir / 'eccv_18_annotation_files'\n",
    "    img_dir = base_dir / 'eccv_18_all_images_sm'\n",
    "    \n",
    "    print(\"\\n=== OUTPUT DIRECTORIES ===\")\n",
    "    print(f\"Base directory: {base_dir}\")\n",
    "    print(f\"Annotation directory: {ann_dir}\")\n",
    "    print(f\"Image directory: {img_dir}\")\n",
    "    print(\"=========================\\n\")\n",
    "    \n",
    "    for dir in [base_dir, ann_dir, img_dir]:\n",
    "        if dir.exists():\n",
    "            shutil.rmtree(dir)\n",
    "        dir.mkdir(parents=True)\n",
    "    \n",
    "    return base_dir, ann_dir, img_dir\n",
    "\n",
    "def count_category_1(json_path):\n",
    "    \"\"\"Count category 1 examples in JSON file\"\"\"\n",
    "    try:\n",
    "        with open(json_path) as f:\n",
    "            data = json.load(f)\n",
    "        return sum(1 for ann in data['annotations'] if ann['category_id'] == 1)\n",
    "    except FileNotFoundError:\n",
    "        return 0\n",
    "\n",
    "def count_category_0(json_path):\n",
    "    \"\"\"Count category 0 examples in JSON file\"\"\"\n",
    "    try:\n",
    "        with open(json_path) as f:\n",
    "            data = json.load(f)\n",
    "        return sum(1 for ann in data['annotations'] if ann['category_id'] == 0)\n",
    "    except FileNotFoundError:\n",
    "        return 0\n",
    "\n",
    "def safe_copy_image(src_path, dst_path, copied_files):\n",
    "    \"\"\"Copy image if it doesn't exist in destination\"\"\"\n",
    "    try:\n",
    "        if src_path.exists() and dst_path.name not in copied_files:\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "            copied_files.add(dst_path.name)\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {src_path}: {e}\")\n",
    "    return False\n",
    "\n",
    "def split_by_ratio(data, ratios=[0.7, 0.2, 0.1]):\n",
    "    \"\"\"Split data by given ratios\"\"\"\n",
    "    n = len(data)\n",
    "    indices = list(range(n))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    cuts = [int(n * ratio) for ratio in ratios]\n",
    "    cuts = [sum(cuts[:i]) for i in range(len(cuts) + 1)]\n",
    "    \n",
    "    return [\n",
    "        [data[i] for i in indices[start:end]]\n",
    "        for start, end in zip(cuts[:-1], cuts[1:])\n",
    "    ]\n",
    "\n",
    "def merge_datasets():\n",
    "    # =====================================================================\n",
    "    # DIRECTORY 2: CHANGE INPUT DIRECTORIES HERE\n",
    "    # =====================================================================\n",
    "    gopro_ann_dir = Path('/mnt/class_data/group4/talen/gopro_preJan21/eccv_18_annotation_files')\n",
    "    farm_ann_dir = Path('/mnt/class_data/group4/talen/farm_output/eccv_18_annotation_files')\n",
    "    gopro_img_dir = Path('/mnt/class_data/group4/talen/gopro_preJan21/eccv_18_all_images_sm')\n",
    "    farm_img_dir = Path('/mnt/class_data/group4/talen/farm_output/eccv_18_all_images_sm')\n",
    "    \n",
    "    print(\"\\n=== INPUT DIRECTORIES ===\")\n",
    "    print(f\"GoPro annotations: {gopro_ann_dir}\")\n",
    "    print(f\"Farm annotations: {farm_ann_dir}\")\n",
    "    print(f\"GoPro images: {gopro_img_dir}\")\n",
    "    print(f\"Farm images: {farm_img_dir}\")\n",
    "    print(\"========================\\n\")\n",
    "    \n",
    "    print(\"\\nInitial Category Counts:\")\n",
    "    print(\"\\nGoPro Dataset:\")\n",
    "    for split in ['train_annotations.json', 'cis_val_annotations.json', 'cis_test_annotations.json']:\n",
    "        cat_1_count = count_category_1(gopro_ann_dir / split)\n",
    "        cat_0_count = count_category_0(gopro_ann_dir / split)\n",
    "        print(f\"{split}:\")\n",
    "        print(f\"  Category 1: {cat_1_count} examples\")\n",
    "        print(f\"  Category 0: {cat_0_count} examples\")\n",
    "\n",
    "    print(\"\\nFarm Dataset:\")\n",
    "    for split in ['train_annotations.json', 'cis_val_annotations.json', 'cis_test_annotations.json']:\n",
    "        cat_1_count = count_category_1(farm_ann_dir / split)\n",
    "        cat_0_count = count_category_0(farm_ann_dir / split)\n",
    "        print(f\"{split}:\")\n",
    "        print(f\"  Category 1: {cat_1_count} examples\")\n",
    "        print(f\"  Category 0: {cat_0_count} examples\")\n",
    "\n",
    "    base_dir, ann_dir, img_dir = setup_directories()\n",
    "    \n",
    "    copied_files = set()\n",
    "    all_images = []\n",
    "    all_annotations = []\n",
    "    next_id = 1\n",
    "    \n",
    "    # Process GoPro dataset\n",
    "    for split in ['train_annotations.json', 'cis_val_annotations.json', 'cis_test_annotations.json']:\n",
    "        data = json.load(open(gopro_ann_dir / split))\n",
    "        for img, ann in zip(data['images'], data['annotations']):\n",
    "            src_path = gopro_img_dir / img['file_name']\n",
    "            dst_path = img_dir / img['file_name']\n",
    "            if safe_copy_image(src_path, dst_path, copied_files):\n",
    "                img['id'] = next_id\n",
    "                ann['image_id'] = next_id\n",
    "                all_images.append(img)\n",
    "                all_annotations.append(ann)\n",
    "                next_id += 1\n",
    "\n",
    "    # Process Farm dataset\n",
    "    farm_splits = {\n",
    "        'train': 'train_annotations.json',\n",
    "        'val': 'cis_val_annotations.json',\n",
    "        'test': 'cis_test_annotations.json'\n",
    "    }\n",
    "    for split in farm_splits.values():\n",
    "        try:\n",
    "            data = json.load(open(farm_ann_dir / split))\n",
    "            for img, ann in zip(data['images'], data['annotations']):\n",
    "                src_path = farm_img_dir / img['file_name']\n",
    "                dst_path = img_dir / img['file_name']\n",
    "                if safe_copy_image(src_path, dst_path, copied_files):\n",
    "                    img['id'] = next_id\n",
    "                    ann['image_id'] = next_id\n",
    "                    all_images.append(img)\n",
    "                    all_annotations.append(ann)\n",
    "                    next_id += 1\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {split} not found in farm dataset\")\n",
    "\n",
    "    # Separate by category\n",
    "    cat_1_records = []\n",
    "    cat_0_records = []\n",
    "    for img, ann in zip(all_images, all_annotations):\n",
    "        record = {'image': img, 'annotation': ann}\n",
    "        if ann['category_id'] == 1:\n",
    "            cat_1_records.append(record)\n",
    "        else:\n",
    "            cat_0_records.append(record)\n",
    "\n",
    "    # Split each category 70/20/10\n",
    "    cat_1_splits = split_by_ratio(cat_1_records)\n",
    "    cat_0_splits = split_by_ratio(cat_0_records)\n",
    "\n",
    "    # Combine splits\n",
    "    splits_data = {\n",
    "        'train_annotations.json': (cat_1_splits[0], cat_0_splits[0]),\n",
    "        'cis_val_annotations.json': (cat_1_splits[1], cat_0_splits[1]),\n",
    "        'cis_test_annotations.json': (cat_1_splits[2], cat_0_splits[2])\n",
    "    }\n",
    "\n",
    "    # Save splits\n",
    "    for filename, (cat_1_records, cat_0_records) in splits_data.items():\n",
    "        records = cat_1_records + cat_0_records\n",
    "        output = {\n",
    "            \"info\": {\"description\": \"Combined dataset\"},\n",
    "            \"images\": [r['image'] for r in records],\n",
    "            \"annotations\": [r['annotation'] for r in records],\n",
    "            \"categories\": [\n",
    "                {\"id\": 1, \"name\": \"forage_fish\"},\n",
    "                {\"id\": 0, \"name\": \"other\"}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        with open(ann_dir / filename, 'w') as f:\n",
    "            json.dump(output, f, indent=4)\n",
    "        \n",
    "        print(f\"\\n{filename}:\")\n",
    "        print(f\"Category 1: {len(cat_1_records)}\")\n",
    "        print(f\"Category 0: {len(cat_0_records)}\")\n",
    "        print(f\"Total: {len(records)}\")\n",
    "\n",
    "    print(f\"\\nTotal unique images copied: {len(copied_files)}\")\n",
    "    print(f\"Total images in combined directory: {len(list(img_dir.glob('*.png')))}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merge_datasets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv4ecology2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
